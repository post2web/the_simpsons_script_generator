{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tokenizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess.p             simpsons_episodes.csv   \u001b[0m\u001b[01;32msimpsons_script_lines.csv\u001b[0m*\r\n",
      "simpsons_characters.csv  simpsons_locations.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>normalized_name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Children</td>\n",
       "      <td>children</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Mechanical Santa</td>\n",
       "      <td>mechanical santa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Tattoo Man</td>\n",
       "      <td>tattoo man</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>DOCTOR ZITSOFSKY</td>\n",
       "      <td>doctor zitsofsky</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Students</td>\n",
       "      <td>students</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              name   normalized_name gender\n",
       "0   7          Children          children    NaN\n",
       "1  12  Mechanical Santa  mechanical santa    NaN\n",
       "2  13        Tattoo Man        tattoo man    NaN\n",
       "3  16  DOCTOR ZITSOFSKY  doctor zitsofsky    NaN\n",
       "4  20          Students          students    NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/simpsons_characters.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "Data from [kaggle](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 8084: expected 13 fields, saw 20\n",
      "Skipping line 52607: expected 13 fields, saw 21\n",
      "Skipping line 59910: expected 13 fields, saw 21\n",
      "\n",
      "Skipping line 71801: expected 13 fields, saw 20\n",
      "Skipping line 73539: expected 13 fields, saw 21\n",
      "Skipping line 77230: expected 13 fields, saw 21\n",
      "Skipping line 78953: expected 13 fields, saw 21\n",
      "Skipping line 81138: expected 13 fields, saw 20\n",
      "Skipping line 86746: expected 13 fields, saw 22\n",
      "Skipping line 101154: expected 13 fields, saw 21\n",
      "Skipping line 115438: expected 13 fields, saw 20\n",
      "Skipping line 117573: expected 13 fields, saw 22\n",
      "Skipping line 130610: expected 13 fields, saw 22\n",
      "\n",
      "Skipping line 152970: expected 13 fields, saw 22\n",
      "Skipping line 153017: expected 13 fields, saw 20\n",
      "Skipping line 153018: expected 13 fields, saw 30\n",
      "Skipping line 154080: expected 13 fields, saw 20\n",
      "Skipping line 154082: expected 13 fields, saw 20\n",
      "Skipping line 154084: expected 13 fields, saw 20\n",
      "Skipping line 154086: expected 13 fields, saw 20\n",
      "Skipping line 154089: expected 13 fields, saw 23\n",
      "Skipping line 154165: expected 13 fields, saw 21\n",
      "Skipping line 156872: expected 13 fields, saw 20\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "text = pd.read_csv('data/simpsons_script_lines.csv', error_bad_lines=False)['raw_text']\n",
    "text = text.str.cat(sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ho've invited us to their homes.\\n\\nLisa Simpson: But Mom, I want to hear the witty banter of sophisticated adults.\\n\\nBart Simpson: Yeah, you can't have any fun in bed.\\n\\nHomer Simpson: (KNOWING CHUCKLE) Oh son, when you're older, you'll know better.\\n\\nHomer Simpson: Hmmm. (SMACKS HIS LIPS) Oh, baby! Mmmm. Yeah.\\n\\nMarge Simpson: (FLUSTERED) Oh! They're here! How does everything look?\\n\\nHomer Simpson: How do I look?\\n\\nMarge Simpson: Do we have enough glasses?\\n\\nHomer Simpson: Do we have enough gag ice cubs?\\n\\nMarge Simpson: Homer! Homer! Put a record on!\\n\\nHomer Simpson: What are all our friends names again?\\n\\nMarge Simpson: Children! Go!\\n\\nNed Flanders: Hey, anybody mind if I serve as bartender? You know, I have a Ph.D in Mixology. (LAUGHS)\\n\\nMoe Szyslak: (UNDER BREATH) College boy.\\n\\nNed Flanders: Hey, Homer! Care to try some of my Flanders Planters punch?\\n\\nHomer Simpson: Why not? I paid for it.\\n\\nHome\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[8000:][100:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before:', 'Miss Hoover: No, actually, it was a little of both. Sometimes when a disease is in all the magazines')\n",
      "('After:', ['[capital]', 'miss', '[space]', '[capital]', 'hoover', '[colon]', '[space]', '[capital]', 'no', '[comma]', '[space]', 'actually', '[comma]', '[space]', 'it', '[space]', 'was', '[space]', 'a', '[space]', 'little', '[space]', 'of', '[space]', 'both', '[period]', '[space]', '[capital]', 'sometimes', '[space]', 'when', '[space]', 'a', '[space]', 'disease', '[space]', 'is', '[space]', 'in', '[space]', 'all', '[space]', 'the', '[space]', 'magazines', '[space]', 'and', '[space]', 'all', '[space]', 'the', '[space]', 'news', '[space]', 'shows', '[comma]', '[space]', 'it', '[apostrophe]', 's', '[space]', 'only', '[space]', 'natural', '[space]', 'that', '[space]', 'you', '[space]', 'think', '[space]', 'you', '[space]', 'have', '[space]', 'it', '[period]', '[return]', '[return]', '[capital]', 'lisa', '[space]', '[capital]', 'simpson', '[colon]', '[space]', '[left_parentheses]', '[capital]', 'near', '[space]', '[capital]', 'tears', '[right_parentheses]', '[space]', '[capital]', 'where', '[apostrophe]', 's', '[space]', '[capital]'])\n"
     ]
    }
   ],
   "source": [
    "print('Before:', text[:100])\n",
    "text = text_to_tokens(text)\n",
    "print('After:', text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create word ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Unique words before filter: ', 41845)\n",
      "('Unique words after filter: ', 2824)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "words_count = pd.Series(Counter(text))\n",
    "print('Unique words before filter: ', len(words_count))\n",
    "\n",
    "# filter non common words to make smallar model\n",
    "words_count = words_count[words_count > 50]\n",
    "print('Unique words after filter: ', len(words_count))\n",
    "\n",
    "words = list(words_count.index)\n",
    "ids = range(len(words))\n",
    "\n",
    "word_to_id = dict(zip(words, ids))\n",
    "id_to_word = dict(zip(ids, words))\n",
    "\n",
    "text_with_ids = []\n",
    "for word in text:\n",
    "    if word not in word_to_id: continue\n",
    "    text_with_ids.append(word_to_id[word])\n",
    "\n",
    "pickle.dump((text_with_ids, word_to_id, id_to_word), open('data/preprocess.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
